---
---

% ============================================================
% 2025
% ============================================================

% 2025 - Preprints (newest first by arxiv number)
@article{tao2025omnizip,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models},
       author = {Tao, Keda and Shao, Kele and Yu, Bohan and Wang, Weiqiang and Liu, Jian and Wang, Huan},
      journal = {arXiv preprint arXiv:2511.14582},
         year = {2025},
        arxiv = {2511.14582},
      preview = {omnizip.png}
}

@article{jin2025mergemix,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding},
       author = {Jin, Xin and Li, Siyuan and Jian, Siyong and Yu, Kai and Wang, Huan},
      journal = {arXiv preprint arXiv:2510.23479},
         year = {2025},
        arxiv = {2510.23479},
      preview = {mergemix.png}
}

@article{chen2025streamingom,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {StreamingTOM: Streaming Token Compression for Efficient Video Understanding},
       author = {Chen, Xueyi and Tao, Keda and Shao, Kele and Wang, Huan},
      journal = {arXiv preprint arXiv:2510.18269},
         year = {2025},
        arxiv = {2510.18269},
      preview = {streamingtom.png}
}

@article{du2025rlkv,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {Which Heads Matter for Reasoning? RL-Guided KV Cache Compression},
       author = {Du, Wenjie and Jiang, Li and Tao, Keda and Liu, Xue and Wang, Huan},
      journal = {arXiv preprint arXiv:2510.08525},
         year = {2025},
        arxiv = {2510.08525},
      preview = {rlkv.png}
}

@article{zhu2025obsdiff,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot},
       author = {Zhu, Junhan and Wang, Hesong and Su, Mingluo and Wang, Zefang and Wang, Huan},
      journal = {arXiv preprint arXiv:2510.06751},
         year = {2025},
        arxiv = {2510.06751},
      preview = {obsdiff.png}
}

@article{feng2025rewardmap,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via Multi-Stage Reinforcement Learning},
       author = {Feng, Sicheng and Tuo, Kaiwen and Wang, Song and Kong, Lingdong and Zhu, Jianke and Wang, Huan},
      journal = {arXiv preprint arXiv:2510.02240},
         year = {2025},
        arxiv = {2510.02240},
      preview = {rewardmap.png}
}

@article{shao2025tokens,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {When Tokens Talk Too Much: A Survey of Multimodal Long-Context Token Compression across Images, Videos, and Audios},
       author = {Shao, Kele and Tao, Keda and Zhang, Kejia and Feng, Sicheng and Cai, Mu and Shang, Yuzhang and You, Haoxuan and Qin, Can and Sui, Yang and Wang, Huan},
      journal = {arXiv preprint arXiv:2507.20198},
         year = {2025},
        arxiv = {2507.20198},
     database = {https://oasis-paddleboat-fc1.notion.site/when-tokens-talk-too-much-database},
   paper_repo = {https://github.com/cokeshao/Awesome-Multimodal-Token-Compression},
      preview = {token_compression_survey.png}
}

@article{tuo2025sparsessm,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {SparseSSM: Efficient Selective Structured State Space Models Can Be Pruned in One-Shot},
       author = {Tuo, Kaiwen and Wang, Huan},
      journal = {arXiv preprint arXiv:2506.09613},
         year = {2025},
        arxiv = {2506.09613},
      preview = {sparsessm.png}
}

@article{bai2025ressvd,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {ResSVD: Residual Compensated SVD for Large Language Model Compression},
       author = {Bai, Haolei and Jian, Siyong and Liang, Tuo and Yin, Yu and Wang, Huan},
      journal = {arXiv preprint arXiv:2505.20112},
         year = {2025},
        arxiv = {2505.20112},
      preview = {ressvd.png}
}

@article{feng2025canmllms,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps},
       author = {Feng, Sicheng and Wang, Song and Ouyang, Shuyi and Kong, Lingdong and Song, Zikai and Zhu, Jianke and Wang, Huan and Wang, Xinchao},
      journal = {arXiv preprint arXiv:2505.18675},
         year = {2025},
        arxiv = {2505.18675},
      website = {https://fscdc.github.io/Reason-Map/},
         code = {https://github.com/fscdc/ReasonMap},
      dataset = {https://huggingface.co/datasets/FSCCS/ReasonMap},
       qbitai = {https://mp.weixin.qq.com/s/sPJLQtHgl5DZghWLWa_H3Q},
      preview = {reasonmap.png}
}

@article{tao2025plugandplay,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {Plug-and-Play 1.x-Bit KV Cache Quantization for Video Large Language Models},
       author = {Tao, Keda and You, Haoxuan and Sui, Yang and Qin, Can and Wang, Huan},
      journal = {arXiv preprint arXiv:2503.16257},
         year = {2025},
        arxiv = {2503.16257},
      preview = {vidkv.png}
}

@article{li2025arpg,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {Autoregressive Image Generation with Randomized Parallel Decoding},
       author = {Li, Haopeng and Yang, Jinyue and Li, Guoqi and Wang, Huan},
      journal = {arXiv preprint arXiv:2503.10568},
         year = {2025},
        arxiv = {2503.10568},
      website = {https://hp-l33.github.io/projects/arpg},
         code = {https://github.com/hp-l33/ARPG},
      preview = {arpg.png}
}

% 2025 - Conference papers
@inproceedings{shao2025holitom,
  bibtex_show = {true},
         abbr = {NeurIPS},
        title = {HoliTom: Holistic Token Merging for Fast Video Large Language Models},
       author = {Shao, Kele and Tao, Keda and Qin, Can and You, Haoxuan and Sui, Yang and Wang, Huan},
    booktitle = {NeurIPS},
         year = {2025},
        arxiv = {2505.21334},
      website = {https://cokeshao.github.io/HoliTom_Web/},
         code = {https://github.com/cokeshao/HoliTom},
      preview = {holitom.jpeg},
     selected = {true}
}

@inproceedings{li2025freqexit,
  bibtex_show = {true},
         abbr = {NeurIPS},
        title = {FreqExit: Enabling Early-Exit Inference for Visual Autoregressive Models via Frequency-Aware Guidance},
       author = {Li, Ying and Lv, Chengfei and Wang, Huan},
    booktitle = {NeurIPS},
         year = {2025},
          pdf = {https://openreview.net/pdf?id=DUlZTgLkeh},
      website = {https://neuraliying.github.io/FreqExit/},
         code = {https://github.com/NeuraLiying/FreqExit},
      preview = {freqexit.png},
     selected = {true}
}

@inproceedings{tao2025dycoke,
  bibtex_show = {true},
         abbr = {CVPR},
        title = {DyCoke: Dynamic Compression of Tokens for Fast Video Large Language Models},
       author = {Tao, Keda and Qin, Can and You, Haoxuan and Sui, Yang and Wang, Huan},
    booktitle = {CVPR},
         year = {2025},
        arxiv = {2411.15024},
         code = {https://github.com/KD-TAO/DyCoke},
      preview = {dycoke.gif},
     selected = {true}
}

@inproceedings{wu2025ondevice,
  bibtex_show = {true},
         abbr = {ICCV},
        title = {On-Device Diffusion Transformer Policy for Efficient Robot Manipulation},
       author = {Wu, Yiming and Wang, Huan and Chen, Zhenghao and Pang, Jianxin and Xu, Dong},
    booktitle = {ICCV},
         year = {2025},
        arxiv = {2508.00697},
      preview = {ondevice_robot.png}
}

@inproceedings{wu2025videopruning,
  bibtex_show = {true},
         abbr = {ACM MM},
        title = {Individual Content and Motion Dynamics Preserved Pruning for Video Diffusion Models},
       author = {Wu, Yiming and Chen, Zhenghao and Wang, Huan and Xu, Dong},
    booktitle = {ACM MM},
         year = {2025},
        arxiv = {2411.18375},
      preview = {videopruning.png}
}

% 2025 - Journal papers
@article{wu2025niagara,
  bibtex_show = {true},
         abbr = {TCSVT},
        title = {Niagara: Normal-Integrated Geometric Affine Field for Scene Reconstruction from a Single View},
       author = {Wu, Xianzu and Ai, Zhenxin and Yang, Harry and Lim, Ser-Nam and Liu, Jun and Wang, Huan},
      journal = {IEEE Transactions on Circuits and Systems for Video Technology},
         year = {2025},
        arxiv = {2503.12553},
      website = {https://ai-kunkun.github.io/Niagara_page/},
         code = {https://github.com/xianzuwu/Niagara},
      preview = {niagara.png}
}

% ============================================================
% 2024
% ============================================================

% 2024 - Preprints
@article{feng2024oracle,
  bibtex_show = {true},
         abbr = {arXiv},
        title = {Is Oracle Pruning the True Oracle?},
       author = {Feng, Sicheng and Tao, Keda and Wang, Huan},
      journal = {arXiv preprint arXiv:2412.00143},
         year = {2024},
        arxiv = {2412.00143},
      website = {https://fscdc.github.io/Oracle-Pruning-Sanity-Check/},
         code = {https://github.com/fscdc/Oracle-Pruning-Sanity-Check},
      preview = {oracle_pruning.jpg}
}

% 2024 - Conference papers
@inproceedings{cao2024simple,
  bibtex_show = {true},
         abbr = {ECCV Oral},
        title = {A Simple Low-bit Quantization Framework for Video Snapshot Compressive Imaging},
       author = {Cao, Miao and Wang, Lishun and Wang, Huan and Yuan, Xin},
    booktitle = {ECCV},
         year = {2024},
        arxiv = {2407.21517},
         code = {https://github.com/mcao92/QuantizedSCI},
      preview = {qsci.png}
}

@inproceedings{cao2024towards,
  bibtex_show = {true},
         abbr = {ACM MM},
        title = {Towards Real-time Video Compressive Sensing on Mobile Devices},
       author = {Cao, Miao and Wang, Lishun and Wang, Huan and Wang, Guoqing and Yuan, Xin},
    booktitle = {ACM MM},
         year = {2024},
        arxiv = {2408.07530},
         code = {https://github.com/mcao92/MobileSCI},
      preview = {mobilesci.png}
}
