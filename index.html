<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Westlake ENCODE Lab </title> <meta name="author" content="Huan Wang"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/westlake_logo.png?185d16fdf455aac37e3389b52da4701e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://westlake-encode-lab.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <img src="/assets/img/EncodeLab_icon.svg" alt="EncodeLab" style="height: 30px; width: auto;"> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">Home <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">Gallery </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Westlake ENCODE Lab </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/people/lab-480.webp 480w,/assets/img/people/lab-800.webp 800w,/assets/img/people/lab-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/people/lab.jpg?329aecdba52329a450866dbb06f67dc1" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="lab.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <center>ENCODE Lab Family</center> </div> </div> <div class="clearfix"> <p><strong>About Us:</strong> <br> The <span style="color: var(--global-theme-color); font-weight: 500">ENCODE Lab</span> (<strong>E</strong>fficient <strong>N</strong>eural network <strong>CO</strong>mputation and <strong>DE</strong>sign) is led by Dr. <a href="https://huanwang.tech/" rel="external nofollow noopener" target="_blank">Huan Wang</a>, a Tenure-Track Assistant Professor in the School of Engineering at <a href="https://en.westlake.edu.cn/faculty/huan-wang.html" rel="external nofollow noopener" target="_blank">Westlake University</a>. We focus on building efficient and reliable AI systems that are scalable and self-improving, driving both theoretical innovation and practical impact.</p> <p><strong>Research Focus:</strong> <br> Our research centers on <strong>Efficient AI</strong>, spanning multiple domains in vision and language:</p> <ul> <li> <strong>LLMs/MLLMs</strong>: [<a href="https://github.com/KD-TAO/DyCoke" rel="external nofollow noopener" target="_blank">DyCoke</a>, <a href="https://github.com/cokeshao/HoliTom" rel="external nofollow noopener" target="_blank">HoliTom</a>, <a href="https://arxiv.org/abs/2511.14582" rel="external nofollow noopener" target="_blank">OmniZip</a>, <a href="https://arxiv.org/abs/2510.23479" rel="external nofollow noopener" target="_blank">MergeMix</a>, <a href="https://arxiv.org/abs/2510.18269" rel="external nofollow noopener" target="_blank">StreamingTOM</a>, <a href="https://arxiv.org/abs/2510.08525" rel="external nofollow noopener" target="_blank">RLKV</a>, <a href="https://arxiv.org/abs/2503.16257" rel="external nofollow noopener" target="_blank">VidKV</a>, <a href="https://arxiv.org/abs/2505.20112" rel="external nofollow noopener" target="_blank">ResSVD</a>, <a href="https://arxiv.org/abs/2506.09613" rel="external nofollow noopener" target="_blank">SparseSSM</a>, <a href="https://fscdc.github.io/Reason-Map/" rel="external nofollow noopener" target="_blank">ReasonMap</a>, <a href="https://arxiv.org/abs/2510.02240" rel="external nofollow noopener" target="_blank">RewardMap</a>, <a href="https://github.com/cokeshao/Awesome-Multimodal-Token-Compression" rel="external nofollow noopener" target="_blank">Survey</a>]</li> <li> <strong>Image Generation</strong> (diffusion/AR models): [<a href="https://arxiv.org/abs/2510.06751" rel="external nofollow noopener" target="_blank">OBS-Diff</a>, <a href="https://arxiv.org/abs/2411.18375" rel="external nofollow noopener" target="_blank">VideoPruning</a>, <a href="https://hp-l33.github.io/projects/arpg" rel="external nofollow noopener" target="_blank">ARPG</a>, <a href="https://neuraliying.github.io/FreqExit/" rel="external nofollow noopener" target="_blank">FreqExit</a>]</li> <li> <strong>3D Reconstruction</strong>: [<a href="https://ai-kunkun.github.io/Niagara_page/" rel="external nofollow noopener" target="_blank">Niagara</a>]</li> <li> <strong>Snapshot Compressive Imaging</strong>: [<a href="https://github.com/mcao92/QuantizedSCI" rel="external nofollow noopener" target="_blank">QuantizedSCI</a>, <a href="https://github.com/mcao92/MobileSCI" rel="external nofollow noopener" target="_blank">MobileSCI</a>]</li> </ul> <p><strong>Join Us:</strong> <br> Our lab is actively recruiting <strong>Ph.D. students</strong> (2026 Fall, 1 position), <strong>Research Assistants</strong> (1 position), and <strong>Visiting Students</strong> to work on Efficient AI (e.g., pruning, quantization, distillation), GenAI (e.g., diffusion models, LLM/MLLM), 3D (e.g., NeRF, Gaussian Splatting), low-level vision (e.g., image restoration), etc. We foster a professional, equal, chill, and creative environment with competitive compensation, sufficient computing resources (H800/A100/A800/A6000/4090), and opportunities for academic collaboration and industry internships. Check out the <a href="https://zhuanlan.zhihu.com/p/691403133" rel="external nofollow noopener" target="_blank">details</a> and fill out <a href="https://encodelab.feishu.cn/share/base/form/shrcnhC3tRR4sPMKlKonhcItEDd" rel="external nofollow noopener" target="_blank">this form</a> to apply!</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vh; overflow-y: auto;"> <table class="table table-sm table-borderless"> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2025/11</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[Funds]</code> We received a research grant from CAAI-Ant Group (CAAI-蚂蚁科研基金). Thank you, CAAI and Ant Group! </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2025/10</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[Preprint]</code> <strong>OBS-Diff</strong>: The <strong>first</strong> paper led by a Westlake <strong>undergraduate</strong> in our lab! Junhan Zhu (Class of 2023) led this work on one-shot pruning for diffusion models. Congrats! [<a href="https://arxiv.org/abs/2510.06751" rel="external nofollow noopener" target="_blank">arxiv</a>] </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2025/09</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[NeurIPS'25]</code> <strong>Four papers</strong> accepted to NeurIPS 2025 in the field of efficient and reliable AI. Congrats to our students and collaborators! Two papers from our lab: <ul> <li> <strong>HoliTom</strong>: A top-performing video LLM token compression method that maintains 99.1% performance while reducing FLOPs to just 6.9%—and it’s training-free! [<a href="https://arxiv.org/abs/2505.21334" rel="external nofollow noopener" target="_blank">arxiv</a>] [<a href="https://github.com/cokeshao/HoliTom" rel="external nofollow noopener" target="_blank">code</a>] [<a href="https://cokeshao.github.io/HoliTom_Web/" rel="external nofollow noopener" target="_blank">webpage</a>] </li> <li> <strong>FreqExit</strong>: A dynamic inference framework for visual autoregressive (VAR) models via early exit with novel frequency-aware guidance. [<a href="https://openreview.net/pdf?id=DUlZTgLkeh" rel="external nofollow noopener" target="_blank">openreview</a>] [<a href="https://github.com/NeuraLiying/FreqExit" rel="external nofollow noopener" target="_blank">code</a>] [<a href="https://neuraliying.github.io/FreqExit/" rel="external nofollow noopener" target="_blank">webpage</a>] </li> </ul> </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2025/09</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[Services]</code> Prof. Huan Wang will serve as an <strong>Area Chair</strong> for AAAI 2026, ICLR 2026, and CVPR 2026. </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2025/07</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[Preprint]</code> We are excited to present the <strong>first</strong> systematic survey on multimodal long-context token compression methods. [<a href="https://arxiv.org/abs/2507.20198" rel="external nofollow noopener" target="_blank">arxiv</a>] [<a href="https://github.com/cokeshao/Awesome-Multimodal-Token-Compression" rel="external nofollow noopener" target="_blank">code</a>] </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2025/07</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[MM'25]</code> Our paper on efficient video diffusion models via network pruning has been accepted to MM’25. Congrats to Yiming! [<a href="https://arxiv.org/abs/2411.18375" rel="external nofollow noopener" target="_blank">arxiv</a>] </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2025/06</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[Award]</code> Congrats to our PhD student <a href="https://kd-tao.github.io/" rel="external nofollow noopener" target="_blank">Keda Tao</a> on receiving the “2025 Westlake University Xinrui Award (西湖大学博士研究生新锐奖)” (<strong>only 2 recipients</strong> in AI among all the 2025 Fall PhD students in School of Engineering)! </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2025/06</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[ICCV'25]</code> Our paper on efficient robot manipulation has been accepted to ICCV’25. Congrats to Yiming! [<a href="https://arxiv.org/abs/2508.00697" rel="external nofollow noopener" target="_blank">arxiv</a>] </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2025/02</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[CVPR'25]</code> <strong>DyCoke</strong> has been accepted to CVPR’25! Congrats to Keda! DyCoke is a training-free, plug-and-play token compression method for fast video LLMs, achieving <strong>1.5x</strong> inference speedup and <strong>1.4x</strong> memory reduction with no performance loss. [<a href="https://arxiv.org/abs/2411.15024" rel="external nofollow noopener" target="_blank">arxiv</a>] [<a href="https://github.com/KD-TAO/DyCoke" rel="external nofollow noopener" target="_blank">code</a>] </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2024/07</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[MM'24]</code> We present the <strong>first</strong> real-time, on-device video SCI (Snapshot Compressive Imaging) framework through dedicated network design and distillation-based training. Congrats to Miao! [<a href="https://arxiv.org/abs/2408.07530" rel="external nofollow noopener" target="_blank">arxiv</a>] [<a href="https://github.com/mcao92/MobileSCI" rel="external nofollow noopener" target="_blank">code</a>] </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2024/07</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[ECCV'24]</code> Our paper on efficient video SCI (Snapshot Compressive Imaging) via network quantization has been accepted to ECCV’24 as an <strong>oral presentation</strong>. Congrats to Miao! [<a href="https://arxiv.org/abs/2407.21517" rel="external nofollow noopener" target="_blank">arxiv</a>] [<a href="https://github.com/mcao92/QuantizedSCI" rel="external nofollow noopener" target="_blank">code</a>] </td> </tr> <tr style="line-height: 1.2; padding-bottom: 0.3rem;"> <th scope="row" style="width: 10%; padding: 0.3rem;">2024/06</th> <td style="padding: 0.2rem;"> <code class="language-plaintext highlighter-rouge">[New Start]</code> Our lab is established! Prof. Huan Wang joins <a href="https://www.westlake.edu.cn/" rel="external nofollow noopener" target="_blank">Westlake University</a> as a tenure-track assistant professor. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100" style="background-color:#6739B7;color:#FFFFFF;"> <div style="color:inherit;">NeurIPS</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/holitom-480.webp 480w,/assets/img/publication_preview/holitom-800.webp 800w,/assets/img/publication_preview/holitom-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/holitom.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="holitom.jpeg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="shao2025holitom" class="col-sm-8"> <div class="title">HoliTom: Holistic Token Merging for Fast Video Large Language Models</div> <div class="author"> <a href="https://cokeshao.github.io/" rel="external nofollow noopener" target="_blank">Kele Shao</a>, <a href="https://kd-tao.github.io/" rel="external nofollow noopener" target="_blank">Keda Tao</a>, <a href="https://canqin.tech/" rel="external nofollow noopener" target="_blank">Can Qin</a>, <a href="https://hxyou.github.io/" rel="external nofollow noopener" target="_blank">Haoxuan You</a>, <a href="https://eclipsess.github.io/yangsui.github.io/" rel="external nofollow noopener" target="_blank">Yang Sui</a>, and <a href="https://huanwang.tech/" rel="external nofollow noopener" target="_blank">Huan Wang</a> </div> <div class="periodical"> <em>NeurIPS</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2505.21334" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> <i class="ai ai-arxiv" style="margin-right: 0.25em;"></i>arXiv </a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/cokeshao/HoliTom" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="margin-right: 0.25em;"></i>Code </a> <a href="https://cokeshao.github.io/HoliTom_Web/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> <i class="fa-solid fa-globe" style="margin-right: 0.25em;"></i>Website </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">shao2025holitom</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{HoliTom: Holistic Token Merging for Fast Video Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Shao, Kele and Tao, Keda and Qin, Can and You, Haoxuan and Sui, Yang and Wang, Huan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100" style="background-color:#6739B7;color:#FFFFFF;"> <div style="color:inherit;">NeurIPS</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/freqexit-480.webp 480w,/assets/img/publication_preview/freqexit-800.webp 800w,/assets/img/publication_preview/freqexit-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/freqexit.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="freqexit.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="li2025freqexit" class="col-sm-8"> <div class="title">FreqExit: Enabling Early-Exit Inference for Visual Autoregressive Models via Frequency-Aware Guidance</div> <div class="author"> <a href="https://neuraliying.github.io/" rel="external nofollow noopener" target="_blank">Ying Li</a>, Chengfei Lv, and <a href="https://huanwang.tech/" rel="external nofollow noopener" target="_blank">Huan Wang</a> </div> <div class="periodical"> <em>NeurIPS</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/pdf?id=DUlZTgLkeh" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/NeuraLiying/FreqExit" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="margin-right: 0.25em;"></i>Code </a> <a href="https://neuraliying.github.io/FreqExit/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> <i class="fa-solid fa-globe" style="margin-right: 0.25em;"></i>Website </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2025freqexit</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FreqExit: Enabling Early-Exit Inference for Visual Autoregressive Models via Frequency-Aware Guidance}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Ying and Lv, Chengfei and Wang, Huan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{NeurIPS}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-4 abbr"> <abbr class="badge rounded w-100" style="background-color:#02379F;color:#FFFFFF;"> <div style="color:inherit;">CVPR</div> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dycoke-480.webp 480w,/assets/img/publication_preview/dycoke-800.webp 800w,/assets/img/publication_preview/dycoke-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/dycoke.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dycoke.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="tao2025dycoke" class="col-sm-8"> <div class="title">DyCoke: Dynamic Compression of Tokens for Fast Video Large Language Models</div> <div class="author"> <a href="https://kd-tao.github.io/" rel="external nofollow noopener" target="_blank">Keda Tao</a>, <a href="https://canqin.tech/" rel="external nofollow noopener" target="_blank">Can Qin</a>, <a href="https://hxyou.github.io/" rel="external nofollow noopener" target="_blank">Haoxuan You</a>, <a href="https://eclipsess.github.io/yangsui.github.io/" rel="external nofollow noopener" target="_blank">Yang Sui</a>, and <a href="https://huanwang.tech/" rel="external nofollow noopener" target="_blank">Huan Wang</a> </div> <div class="periodical"> <em>CVPR</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2411.15024" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> <i class="ai ai-arxiv" style="margin-right: 0.25em;"></i>arXiv </a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/KD-TAO/DyCoke" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank"> <i class="fa-brands fa-github" style="margin-right: 0.25em;"></i>Code </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tao2025dycoke</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DyCoke: Dynamic Compression of Tokens for Fast Video Large Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tao, Keda and Qin, Can and You, Haoxuan and Sui, Yang and Wang, Huan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{CVPR}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%77%61%6E%67%68%75%61%6E@%77%65%73%74%6C%61%6B%65.%65%64%75.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/westlake-encode-lab" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 ENCODE Lab. Last updated: 2025/12/13. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>